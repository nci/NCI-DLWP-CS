{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a DLWP-CS model\n",
    "\n",
    "- Now we use the data processed in the previous two notebooks to train a convolutional neural network on weather data mapped to the cubed sphere. We will construct the same convolutional neural network with the cubed sphere as in *Weyn et al. (2020)*, with the exception of having only two variables (Z500 and T2) instead of their four, and without the constant land-sea mask and topography data. \n",
    "- This will seem like a fairly involved example but much simpler constructions are also possible using the `DLWPNeuralNet` class instead of the functional Keras API. Authors recommend using a GPU with at least 4 GB RAM.\n",
    "\n",
    "#### Required packages\n",
    "\n",
    "No new packages are needed here beyond the main DLWP-CS requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Let's start with some basic user-selected parameters, beginning with the file paths, which you'll need to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async' \n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print (gpus)\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_directory: /scratch/vp91/mah900/NCI-DLWP-CS/Data/\n",
      "predictor_file: /g/data/dk92/data/NCI-DLWP-CS/Data/NCI_tutorial/NCI_tutorial_z500_t2m_CS.nc\n",
      "model_file:     /scratch/vp91/mah900/NCI-DLWP-CS/Data/dlwp-cs_NCI_tutorial\n",
      "log_directory:  /scratch/vp91/mah900/NCI-DLWP-CS/Data/logs/dlwp-cs_NCI_tutorial\n"
     ]
    }
   ],
   "source": [
    "!export TF_GPU_ALLOCATOR=cuda_malloc_async \n",
    "import os\n",
    "os.chdir (f\"/scratch/vp91/{os.environ['USER']}/NCI-DLWP-CS\")\n",
    "root_directory = f\"/scratch/vp91/{os.environ['USER']}/NCI-DLWP-CS/Data/\"\n",
    "# From your selected dir\n",
    "#predictor_file = os.path.join(root_directory, 'NCI_tutorial', 'NCI_tutorial_z500_t2m_CS.nc')\n",
    "# From dk92\n",
    "predictor_file = '/g/data/dk92/data/NCI-DLWP-CS/Data/NCI_tutorial/NCI_tutorial_z500_t2m_CS.nc'\n",
    "\n",
    "model_file = os.path.join(root_directory, 'dlwp-cs_NCI_tutorial')\n",
    "log_directory = os.path.join(root_directory, 'logs', 'dlwp-cs_NCI_tutorial')\n",
    "\n",
    "print (\"root_directory:\", root_directory)\n",
    "print (\"predictor_file:\", predictor_file)\n",
    "print (\"model_file:    \", model_file)\n",
    "print (\"log_directory: \", log_directory )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some parameters:  \n",
    "- `cnn_model_name`: name of the function which constructs the model  \n",
    "- `base_filter_number`: number of convolutional filters in the first convolutional layer  \n",
    "- `min_epochs`: minimum number of training epochs  \n",
    "- `max_epochs`: maximum number of training epochs  \n",
    "- `patience`: if the validation loss does not go down for this number of epochs, end training  \n",
    "- `batch_size`: for mini-batches for SGD training  \n",
    "- `shuffle`: if True, shuffles the training data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_name = 'unet2'\n",
    "base_filter_number = 32\n",
    "min_epochs = 0\n",
    "# For GPU\n",
    "#max_epochs = 20\n",
    "# For CPU\n",
    "max_epochs = 2\n",
    "patience = 2\n",
    "batch_size = 32\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable selection. This follows the coordinates in the data file. Make sure to use lists to avoid losing dimensions. Set `add_solar` to True to include insolation variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_selection = {'varlev': ['z/500', 't2m/0']}\n",
    "add_solar = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters govern the time stepping in the model.  \n",
    "- `io_time_steps`: the number of input/output time steps directly ingested/predicted by the model  \n",
    "- `integration_steps`: the number of forward sequence steps on which to minimize the loss function of the model  \n",
    "- `data_interval`: the number of steps in the data file that constitute a \"time step.\" Here we use 2, and the data contains data every 3 hours, so the effective time step is 6 h.\n",
    "- `loss_by_step`: either None (equal weighting) or a list of weighting factors for the loss function at each integration step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_time_steps = 2\n",
    "integration_steps = 2\n",
    "data_interval = 2\n",
    "loss_by_step = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the data used for validation and training. Here we use 2013-14 for training and 2015-16 for validation, leaving aside 2017-18 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_set = list(pd.date_range('2013-01-01', '2014-12-31 21:00', freq='3h'))\n",
    "validation_set = list(pd.date_range('2015-01-01', '2016-12-31 21:00', freq='3h'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you have a newer Nvidia GPU (Tesla V100, GeForce RTX series) with tensor cores, you can enable mixed precision for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mp_optimizer = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DLWP model\n",
    "\n",
    "Since the data generators depend on the model (granted it's an outdated dependency), we make the model instance first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DLWP.model import DLWPFunctional\n",
    "\n",
    "dlwp = DLWPFunctional(is_convolutional=True, time_dim=io_time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and create data generators\n",
    "\n",
    "DLWP-CS includes powerful data generators that produce batches of training data on-the-fly. \n",
    "- This enables them to load only the time series into memory instead of repetitive samples of data. \n",
    "- On the downside, it makes reading training data from disk virtually impossibly slow. First, load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "data = xr.open_dataset(predictor_file)\n",
    "train_data = data.sel(sample=train_set)\n",
    "validation_data = data.sel(sample=validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training data generator. Here we use the `ArrayDataGenerator` class, which has a nifty pre-processing function to create a single numpy array of data. The `SeriesDataGenerator` is more intuitive and would work equally well. (Authors recommended to use the latter is because of the overhead when using xarray objects instead of pure numpy might slow things down.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data to memory...\n"
     ]
    }
   ],
   "source": [
    "from DLWP.model.preprocessing import prepare_data_array\n",
    "from DLWP.model import ArrayDataGenerator\n",
    "\n",
    "print('Loading data to memory...')\n",
    "train_array, input_ind, output_ind, sol = prepare_data_array(train_data, input_sel=io_selection,\n",
    "                                                             output_sel=io_selection, add_insolation=add_solar)\n",
    "generator = ArrayDataGenerator(dlwp, train_array, rank=3, input_slice=input_ind, output_slice=output_ind,\n",
    "                               input_time_steps=io_time_steps, output_time_steps=io_time_steps,\n",
    "                               sequence=integration_steps, interval=data_interval, insolation_array=sol,\n",
    "                               batch_size=batch_size, shuffle=shuffle, channels_last=True,\n",
    "                               drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data to memory...\n"
     ]
    }
   ],
   "source": [
    "print('Loading validation data to memory...')\n",
    "val_array, input_ind, output_ind, sol = prepare_data_array(validation_data, input_sel=io_selection,\n",
    "                                                           output_sel=io_selection, add_insolation=add_solar)\n",
    "val_generator = ArrayDataGenerator(dlwp, val_array, rank=3, input_slice=input_ind, output_slice=output_ind,\n",
    "                                   input_time_steps=io_time_steps, output_time_steps=io_time_steps,\n",
    "                                   sequence=integration_steps, interval=data_interval, insolation_array=sol,\n",
    "                                   batch_size=batch_size, shuffle=False, channels_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since TensorFlow 2.0, using `multiprocessing` in training Keras models has bad behavior (memory leaks). Therefore, for better performance, it is recommend to using the `tf_data_generator` function to create a `tensorflow.data.Dataset` generator object. It does require knowing the names of the inputs and outputs to use this (see the cell below). This will become more evident in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DLWP.model import tf_data_generator\n",
    "\n",
    "input_names = ['main_input'] + ['solar_%d' % i for i in range(1, integration_steps)]\n",
    "tf_train_data = tf_data_generator(generator, batch_size=batch_size, input_names=input_names)\n",
    "tf_val_data = tf_data_generator(val_generator, input_names=input_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the CNN model architecture\n",
    "\n",
    "Now the fun part! Here we create all of the layers that will go into the model. A few notes:  \n",
    "- The generator produces a list of inputs when `integration_steps` is greater than 1:  \n",
    "  - main input, including insolation  \n",
    "  - insolation for step 2  \n",
    "  - insolation for step 3...  \n",
    "- We use our custom layers for padding and convolutions on the cubed sphere  \n",
    "- We can use the Keras 3D layers for operations on the 3D spatial structure of the cubed sphere\n",
    "- There are more layers defined here than actually used in the model architecture. That's ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, UpSampling3D, AveragePooling3D, concatenate, ReLU, Reshape, Concatenate, \\\n",
    "    Permute\n",
    "from DLWP.custom import CubeSpherePadding2D, CubeSphereConv2D\n",
    "\n",
    "# Some shortcut variables. The generator provides the expected shape of the data.\n",
    "cs = generator.convolution_shape\n",
    "cso = generator.output_convolution_shape\n",
    "input_solar = (integration_steps > 1 and add_solar)\n",
    "\n",
    "# Define layers. Must be defined outside of model function so we use the same weights at each integration step.\n",
    "main_input = Input(shape=cs, name='main_input')\n",
    "if input_solar:\n",
    "    solar_inputs = [Input(shape=generator.insolation_shape, name='solar_%d' % d) for d in range(1, integration_steps)]\n",
    "cube_padding_1 = CubeSpherePadding2D(1, data_format='channels_last')\n",
    "pooling_2 = AveragePooling3D((1, 2, 2), data_format='channels_last')\n",
    "up_sampling_2 = UpSampling3D((1, 2, 2), data_format='channels_last')\n",
    "relu = ReLU(negative_slope=0.1, max_value=10.)\n",
    "conv_kwargs = {\n",
    "    'dilation_rate': 1,\n",
    "    'padding': 'valid',\n",
    "    'activation': 'linear',\n",
    "    'data_format': 'channels_last'\n",
    "}\n",
    "skip_connections = 'unet' in cnn_model_name.lower()\n",
    "conv_2d_1 = CubeSphereConv2D(base_filter_number, 3, **conv_kwargs)\n",
    "conv_2d_1_2 = CubeSphereConv2D(base_filter_number, 3, **conv_kwargs)\n",
    "conv_2d_1_3 = CubeSphereConv2D(base_filter_number, 3, **conv_kwargs)\n",
    "conv_2d_2 = CubeSphereConv2D(base_filter_number * 2, 3, **conv_kwargs)\n",
    "conv_2d_2_2 = CubeSphereConv2D(base_filter_number * 2, 3, **conv_kwargs)\n",
    "conv_2d_2_3 = CubeSphereConv2D(base_filter_number * 2, 3, **conv_kwargs)\n",
    "conv_2d_3 = CubeSphereConv2D(base_filter_number * 4, 3, **conv_kwargs)\n",
    "conv_2d_3_2 = CubeSphereConv2D(base_filter_number * 4, 3, **conv_kwargs)\n",
    "conv_2d_4 = CubeSphereConv2D(base_filter_number * 4 if skip_connections else base_filter_number * 8, 3, **conv_kwargs)\n",
    "conv_2d_4_2 = CubeSphereConv2D(base_filter_number * 8, 3, **conv_kwargs)\n",
    "conv_2d_5 = CubeSphereConv2D(base_filter_number * 2 if skip_connections else base_filter_number * 4, 3, **conv_kwargs)\n",
    "conv_2d_5_2 = CubeSphereConv2D(base_filter_number * 4, 3, **conv_kwargs)\n",
    "conv_2d_5_3 = CubeSphereConv2D(base_filter_number * 4, 3, **conv_kwargs)\n",
    "conv_2d_6 = CubeSphereConv2D(base_filter_number if skip_connections else base_filter_number * 2, 3, **conv_kwargs)\n",
    "conv_2d_6_2 = CubeSphereConv2D(base_filter_number * 2, 3, **conv_kwargs)\n",
    "conv_2d_6_3 = CubeSphereConv2D(base_filter_number * 2, 3, **conv_kwargs)\n",
    "conv_2d_7 = CubeSphereConv2D(base_filter_number, 3, **conv_kwargs)\n",
    "conv_2d_7_2 = CubeSphereConv2D(base_filter_number, 3, **conv_kwargs)\n",
    "conv_2d_7_3 = CubeSphereConv2D(base_filter_number, 3, **conv_kwargs)\n",
    "conv_2d_8 = CubeSphereConv2D(cso[-1], 1, name='output', **conv_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually create the output using the functional API. For each operation in the model, we call the appropriate layer on an input tensor `x`. This function performs the operations inside a U-Net, including the skipped connections with concatenation along the channels dimension. This is the sequence of operations to get input data to a prediction, but it is not the whole model, since that one must predict a sequence of 2 (`integration_steps = 2`). That will be next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet2(x):\n",
    "    x0 = cube_padding_1(x)\n",
    "    x0 = relu(conv_2d_1(x0))\n",
    "    x0 = cube_padding_1(x0)\n",
    "    x0 = relu(conv_2d_1_2(x0))\n",
    "    x1 = pooling_2(x0)\n",
    "    x1 = cube_padding_1(x1)\n",
    "    x1 = relu(conv_2d_2(x1))\n",
    "    x1 = cube_padding_1(x1)\n",
    "    x1 = relu(conv_2d_2_2(x1))\n",
    "    x2 = pooling_2(x1)\n",
    "    x2 = cube_padding_1(x2)\n",
    "    x2 = relu(conv_2d_5_2(x2))\n",
    "    x2 = cube_padding_1(x2)\n",
    "    x2 = relu(conv_2d_5(x2))\n",
    "    x2 = up_sampling_2(x2)\n",
    "    x = concatenate([x2, x1], axis=-1)\n",
    "    x = cube_padding_1(x)\n",
    "    x = relu(conv_2d_6_2(x))\n",
    "    x = cube_padding_1(x)\n",
    "    x = relu(conv_2d_6(x))\n",
    "    x = up_sampling_2(x)\n",
    "    x = concatenate([x, x0], axis=-1)\n",
    "    x = cube_padding_1(x)\n",
    "    x = relu(conv_2d_7(x))\n",
    "    x = cube_padding_1(x)\n",
    "    x = relu(conv_2d_7_2(x))\n",
    "    x = conv_2d_8(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we manipulate the result of the CNN back to inputs to the same CNN, add the new insolation input, and pass it through again. This allows us to minimize the loss function at each step of the sequence. Adding the insolation looks complicated because the array includes a time dimension whereas the data inputs are flattened time/variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape, Concatenate, Permute\n",
    "\n",
    "def complete_model(x_in):\n",
    "    outputs = []\n",
    "    model_function = globals()[cnn_model_name]\n",
    "    is_seq = isinstance(x_in, (list, tuple))\n",
    "    xi = x_in[0] if is_seq else x_in\n",
    "    outputs.append(model_function(xi))\n",
    "    for step in range(1, integration_steps):\n",
    "        xo = outputs[step - 1]\n",
    "        if is_seq and input_solar:\n",
    "            xo = Reshape(cs[:-1] + (io_time_steps, -1))(xo)\n",
    "            xo = Concatenate(axis=-1)([xo, Permute((2, 3, 4, 1, 5))(x_in[step])])\n",
    "            xo = Reshape(cs)(xo)\n",
    "        outputs.append(model_function(xo))\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use our known inputs to get the outputs from `complete_model` and construct a Keras Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "if not input_solar:\n",
    "    inputs = main_input\n",
    "else:\n",
    "    inputs = [main_input]\n",
    "    if input_solar:\n",
    "        inputs = inputs + solar_inputs\n",
    "model = Model(inputs=inputs, outputs=complete_model(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a loss function and an optimizer. We use the default mean-squared-error and the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "loss_function = 'mse'\n",
    "\n",
    "# Get an optimizer, with mixed precision if requested\n",
    "opt = Adam()\n",
    "if use_mp_optimizer:\n",
    "    opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to compile our DLWP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " main_input (InputLayer)     [(None, 6, 48, 48, 6)]       0         []                            \n",
      "                                                                                                  \n",
      " cube_sphere_padding2d (Cub  multiple                     0         ['main_input[0][0]',          \n",
      " eSpherePadding2D)                                                   're_lu[0][0]',               \n",
      "                                                                     'average_pooling3d[0][0]',   \n",
      "                                                                     're_lu[2][0]',               \n",
      "                                                                     'average_pooling3d[1][0]',   \n",
      "                                                                     're_lu[4][0]',               \n",
      "                                                                     'concatenate[0][0]',         \n",
      "                                                                     're_lu[6][0]',               \n",
      "                                                                     'concatenate_1[0][0]',       \n",
      "                                                                     're_lu[8][0]',               \n",
      "                                                                     'reshape_1[0][0]',           \n",
      "                                                                     're_lu[10][0]',              \n",
      "                                                                     'average_pooling3d[2][0]',   \n",
      "                                                                     're_lu[12][0]',              \n",
      "                                                                     'average_pooling3d[3][0]',   \n",
      "                                                                     're_lu[14][0]',              \n",
      "                                                                     'concatenate_3[0][0]',       \n",
      "                                                                     're_lu[16][0]',              \n",
      "                                                                     'concatenate_4[0][0]',       \n",
      "                                                                     're_lu[18][0]']              \n",
      "                                                                                                  \n",
      " cube_sphere_conv2d (CubeSp  (None, 6, 48, 48, 32)        3520      ['cube_sphere_padding2d[0][0]'\n",
      " hereConv2D)                                                        , 'cube_sphere_padding2d[10][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                multiple                     0         ['cube_sphere_conv2d[0][0]',  \n",
      "                                                                     'cube_sphere_conv2d_1[0][0]',\n",
      "                                                                     'cube_sphere_conv2d_3[0][0]',\n",
      "                                                                     'cube_sphere_conv2d_4[0][0]',\n",
      "                                                                     'cube_sphere_conv2d_11[0][0]'\n",
      "                                                                    , 'cube_sphere_conv2d_10[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'cube_sphere_conv2d_14[0][0]'\n",
      "                                                                    , 'cube_sphere_conv2d_13[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'cube_sphere_conv2d_16[0][0]'\n",
      "                                                                    , 'cube_sphere_conv2d_17[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'cube_sphere_conv2d[1][0]',  \n",
      "                                                                     'cube_sphere_conv2d_1[1][0]',\n",
      "                                                                     'cube_sphere_conv2d_3[1][0]',\n",
      "                                                                     'cube_sphere_conv2d_4[1][0]',\n",
      "                                                                     'cube_sphere_conv2d_11[1][0]'\n",
      "                                                                    , 'cube_sphere_conv2d_10[1][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'cube_sphere_conv2d_14[1][0]'\n",
      "                                                                    , 'cube_sphere_conv2d_13[1][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'cube_sphere_conv2d_16[1][0]'\n",
      "                                                                    , 'cube_sphere_conv2d_17[1][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " cube_sphere_conv2d_1 (Cube  (None, 6, 48, 48, 32)        18496     ['cube_sphere_padding2d[1][0]'\n",
      " SphereConv2D)                                                      , 'cube_sphere_padding2d[11][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " average_pooling3d (Average  multiple                     0         ['re_lu[1][0]',               \n",
      " Pooling3D)                                                          're_lu[3][0]',               \n",
      "                                                                     're_lu[11][0]',              \n",
      "                                                                     're_lu[13][0]']              \n",
      "                                                                                                  \n",
      " cube_sphere_conv2d_3 (Cube  (None, 6, 24, 24, 64)        36992     ['cube_sphere_padding2d[2][0]'\n",
      " SphereConv2D)                                                      , 'cube_sphere_padding2d[12][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " cube_sphere_conv2d_4 (Cube  (None, 6, 24, 24, 64)        73856     ['cube_sphere_padding2d[3][0]'\n",
      " SphereConv2D)                                                      , 'cube_sphere_padding2d[13][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " cube_sphere_conv2d_11 (Cub  (None, 6, 12, 12, 128)       147712    ['cube_sphere_padding2d[4][0]'\n",
      " eSphereConv2D)                                                     , 'cube_sphere_padding2d[14][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " cube_sphere_conv2d_10 (Cub  (None, 6, 12, 12, 64)        147584    ['cube_sphere_padding2d[5][0]'\n",
      " eSphereConv2D)                                                     , 'cube_sphere_padding2d[15][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " up_sampling3d (UpSampling3  multiple                     0         ['re_lu[5][0]',               \n",
      " D)                                                                  're_lu[7][0]',               \n",
      "                                                                     're_lu[15][0]',              \n",
      "                                                                     're_lu[17][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 6, 24, 24, 128)       0         ['up_sampling3d[0][0]',       \n",
      "                                                                     're_lu[3][0]']               \n",
      "                                                                                                  \n",
      " cube_sphere_conv2d_14 (Cub  (None, 6, 24, 24, 64)        147584    ['cube_sphere_padding2d[6][0]'\n",
      " eSphereConv2D)                                                     , 'cube_sphere_padding2d[16][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " cube_sphere_conv2d_13 (Cub  (None, 6, 24, 24, 32)        36928     ['cube_sphere_padding2d[7][0]'\n",
      " eSphereConv2D)                                                     , 'cube_sphere_padding2d[17][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 6, 48, 48, 64)        0         ['up_sampling3d[1][0]',       \n",
      " )                                                                   're_lu[1][0]']               \n",
      "                                                                                                  \n",
      " cube_sphere_conv2d_16 (Cub  (None, 6, 48, 48, 32)        36928     ['cube_sphere_padding2d[8][0]'\n",
      " eSphereConv2D)                                                     , 'cube_sphere_padding2d[18][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " cube_sphere_conv2d_17 (Cub  (None, 6, 48, 48, 32)        18496     ['cube_sphere_padding2d[9][0]'\n",
      " eSphereConv2D)                                                     , 'cube_sphere_padding2d[19][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " output (CubeSphereConv2D)   (None, 6, 48, 48, 4)         264       ['re_lu[9][0]',               \n",
      "                                                                     're_lu[19][0]']              \n",
      "                                                                                                  \n",
      " solar_1 (InputLayer)        [(None, 2, 6, 48, 48, 1)]    0         []                            \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 6, 48, 48, 2, 2)      0         ['output[0][0]']              \n",
      "                                                                                                  \n",
      " permute (Permute)           (None, 6, 48, 48, 2, 1)      0         ['solar_1[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 6, 48, 48, 2, 3)      0         ['reshape[0][0]',             \n",
      " )                                                                   'permute[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 6, 48, 48, 6)         0         ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 6, 24, 24, 128)       0         ['up_sampling3d[2][0]',       \n",
      " )                                                                   're_lu[13][0]']              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 6, 48, 48, 64)        0         ['up_sampling3d[3][0]',       \n",
      " )                                                                   're_lu[11][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 668360 (2.55 MB)\n",
      "Trainable params: 668360 (2.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dlwp.build_model(model, loss=loss_function, loss_weights=loss_by_step, optimizer=opt, metrics=['mae'])\n",
    "print(dlwp.base_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the DLWP model\n",
    "\n",
    "Now let's train the model. First, define a few callbacks:\n",
    "- `history`: save the model metrics as it trains  \n",
    "- `early`: a custom callback used to stop training after `patience` epochs, but only after a minimum number of epochs  \n",
    "- `tensorboard`: TensorFlow's complete logging  \n",
    "- `GeneratorEpochEnd`: when using `tf_data_generator`, this is used to shuffle the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import History, TensorBoard\n",
    "from DLWP.custom import EarlyStoppingMin, SaveWeightsOnEpoch, GeneratorEpochEnd\n",
    "\n",
    "history = History()\n",
    "early = EarlyStoppingMin(monitor='val_loss' if validation_data is not None else 'loss', min_delta=0.,\n",
    "                         min_epochs=min_epochs, max_epochs=max_epochs, patience=patience,\n",
    "                         restore_best_weights=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=log_directory, update_freq='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model! Don't worry about warnings about the data sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724651202.091397 1778870 service.cc:145] XLA service 0x14fb324b1250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1724651202.091428 1778870 service.cc:153]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1724651202.231518 1778870 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 111s 385ms/step - loss: 0.0937 - output_loss: 0.0383 - output_1_loss: 0.0554 - output_mae: 0.1199 - output_1_mae: 0.1415 - val_loss: 0.0294 - val_output_loss: 0.0132 - val_output_1_loss: 0.0161 - val_output_mae: 0.0752 - val_output_1_mae: 0.0858\n",
      "Epoch 2/21\n",
      "182/182 [==============================] - 62s 343ms/step - loss: 0.0249 - output_loss: 0.0111 - output_1_loss: 0.0138 - output_mae: 0.0691 - output_1_mae: 0.0799 - val_loss: 0.0214 - val_output_loss: 0.0091 - val_output_1_loss: 0.0123 - val_output_mae: 0.0631 - val_output_1_mae: 0.0746\n",
      "Epoch 3/21\n",
      "182/182 [==============================] - 62s 343ms/step - loss: 0.0182 - output_loss: 0.0078 - output_1_loss: 0.0104 - output_mae: 0.0581 - output_1_mae: 0.0700 - val_loss: 0.0154 - val_output_loss: 0.0065 - val_output_1_loss: 0.0089 - val_output_mae: 0.0532 - val_output_1_mae: 0.0638\n",
      "Epoch 4/21\n",
      "182/182 [==============================] - 63s 343ms/step - loss: 0.0147 - output_loss: 0.0061 - output_1_loss: 0.0086 - output_mae: 0.0515 - output_1_mae: 0.0638 - val_loss: 0.0141 - val_output_loss: 0.0056 - val_output_1_loss: 0.0085 - val_output_mae: 0.0490 - val_output_1_mae: 0.0629\n",
      "Epoch 5/21\n",
      "182/182 [==============================] - 62s 343ms/step - loss: 0.0130 - output_loss: 0.0052 - output_1_loss: 0.0077 - output_mae: 0.0475 - output_1_mae: 0.0601 - val_loss: 0.0130 - val_output_loss: 0.0051 - val_output_1_loss: 0.0079 - val_output_mae: 0.0476 - val_output_1_mae: 0.0638\n",
      "Epoch 6/21\n",
      "182/182 [==============================] - 63s 344ms/step - loss: 0.0118 - output_loss: 0.0047 - output_1_loss: 0.0071 - output_mae: 0.0450 - output_1_mae: 0.0578 - val_loss: 0.0115 - val_output_loss: 0.0045 - val_output_1_loss: 0.0069 - val_output_mae: 0.0440 - val_output_1_mae: 0.0571\n",
      "Epoch 7/21\n",
      "182/182 [==============================] - 63s 344ms/step - loss: 0.0113 - output_loss: 0.0045 - output_1_loss: 0.0068 - output_mae: 0.0439 - output_1_mae: 0.0563 - val_loss: 0.0106 - val_output_loss: 0.0042 - val_output_1_loss: 0.0064 - val_output_mae: 0.0421 - val_output_1_mae: 0.0538\n",
      "Epoch 8/21\n",
      "182/182 [==============================] - 62s 343ms/step - loss: 0.0105 - output_loss: 0.0041 - output_1_loss: 0.0063 - output_mae: 0.0421 - output_1_mae: 0.0547 - val_loss: 0.0103 - val_output_loss: 0.0040 - val_output_1_loss: 0.0063 - val_output_mae: 0.0412 - val_output_1_mae: 0.0537\n",
      "Epoch 9/21\n",
      "182/182 [==============================] - 62s 343ms/step - loss: 0.0100 - output_loss: 0.0039 - output_1_loss: 0.0061 - output_mae: 0.0410 - output_1_mae: 0.0534 - val_loss: 0.0105 - val_output_loss: 0.0039 - val_output_1_loss: 0.0065 - val_output_mae: 0.0407 - val_output_1_mae: 0.0539\n",
      "Epoch 10/21\n",
      "182/182 [==============================] - 62s 343ms/step - loss: 0.0097 - output_loss: 0.0038 - output_1_loss: 0.0059 - output_mae: 0.0403 - output_1_mae: 0.0530 - val_loss: 0.0094 - val_output_loss: 0.0037 - val_output_1_loss: 0.0057 - val_output_mae: 0.0393 - val_output_1_mae: 0.0508\n",
      "Epoch 11/21\n",
      "182/182 [==============================] - 62s 343ms/step - loss: 0.0096 - output_loss: 0.0037 - output_1_loss: 0.0059 - output_mae: 0.0402 - output_1_mae: 0.0530 - val_loss: 0.0101 - val_output_loss: 0.0039 - val_output_1_loss: 0.0063 - val_output_mae: 0.0405 - val_output_1_mae: 0.0533\n",
      "Epoch 12/21\n",
      "182/182 [==============================] - ETA: 0s - loss: 0.0089 - output_loss: 0.0035 - output_1_loss: 0.0054 - output_mae: 0.0387 - output_1_mae: 0.0506Restoring model weights from the end of the best epoch\n",
      "182/182 [==============================] - 63s 344ms/step - loss: 0.0089 - output_loss: 0.0035 - output_1_loss: 0.0054 - output_mae: 0.0387 - output_1_mae: 0.0506 - val_loss: 0.0098 - val_output_loss: 0.0036 - val_output_1_loss: 0.0061 - val_output_mae: 0.0401 - val_output_1_mae: 0.0553\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "dlwp.fit_generator(tf_train_data, epochs=max_epochs + 1,\n",
    "                   verbose=1, validation_data=tf_val_data,\n",
    "                   callbacks=[history, early, GeneratorEpochEnd(generator)])\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model. We use the DLWP utility function, which saves the DLWP instance as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote model: /scratch/vp91/mah900/NCI-DLWP-CS/Data/dlwp-cs_NCI_tutorial\n"
     ]
    }
   ],
   "source": [
    "from DLWP.util import save_model\n",
    "\n",
    "save_model(dlwp, model_file, history=history)\n",
    "print('Wrote model: %s' % model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, print some loss metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train time: 798.518657207489 seconds \n",
      "Validation loss: 0.009369230829179287\n",
      "Other scores: [0.0036647114902734756, 0.0057045165449380875, 0.03927592188119888, 0.050840113312006]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain time: %s seconds \" % (end_time - start_time))\n",
    "\n",
    "score = dlwp.evaluate(*val_generator.generate([]), verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Other scores:', score[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! You have successfully trained a pure machine-learning global weather prediction model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
